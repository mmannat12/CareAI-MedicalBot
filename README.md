# ğŸ©º CareAI - AI-Powered Medical Chatbot using LLMs + RAG

**CareAI** is an intelligent, document-aware medical chatbot built using **Large Language Models (LLMs)** and **Retrieval-Augmented Generation (RAG)**. It uses vector embeddings to search relevant content from **The Gale Encyclopedia of Medicine (PDF)** and generates accurate, context-driven answers to health-related queries.

---

## ğŸ› ï¸ Tech Stack

* **Python** ğŸ
* **LLaMA 3.2** ğŸ§  â€“ Large Language Model for answer generation
* **LangChain** ğŸ”— â€“ Orchestration of retrieval and generation
* **Pinecone** ğŸŒ² â€“ Vector database for similarity search
* **Flask** ğŸŒ â€“ Lightweight backend for chatbot API
* **PyMuPDF (fitz)** ğŸ“„ â€“ PDF parsing and chunking
* **sentence-transformers** ğŸ’¬ â€“ Text embedding generation
* **HTML/CSS/JS** ğŸ¨ â€“ Simple and responsive frontend interface

---

## âœ¨ Features

* ğŸ“„ Uses *The Gale Encyclopedia of Medicine* as a trusted knowledge base
* ğŸ” RAG-powered responses: retrieves relevant context before answering
* ğŸ¤– Uses **LLaMA 3.2** for domain-specific response generation
* ğŸ§  Fast and accurate **semantic search** with Pinecone
* ğŸ’¬ Clean web-based chat interface via Flask
* ğŸ“‚ Modular codebase for easy customization and scaling

---

## ğŸ” How It Works

1. **PDF Parsing**: The PDF of *The Gale Encyclopedia of Medicine* is parsed using `PyMuPDF`, and text is chunked intelligently.
2. **Embedding Generation**: Each chunk is converted into high-dimensional vectors using `sentence-transformers`.
3. **Vector Storage**: The embeddings are stored in **Pinecone** for efficient semantic retrieval.
4. **Query Input**: User enters a medical question in the web interface.
5. **RAG Pipeline**: LangChain fetches relevant chunks using Pinecone and passes them to **LLaMA 3.2** to generate an informed answer.
6. **Response Display**: The chatbot responds via the frontend with text output.

---

## ğŸ—‚ï¸ Project Structure

```
CareAI-MedicalBot/
â”‚
â”œâ”€â”€ data/                     # Gale Encyclopedia of Medicine PDF
â”œâ”€â”€ embeddings/               # Saved chunk embeddings (optional cache)
â”œâ”€â”€ app.py                    # Flask backend application
â”œâ”€â”€ ingest.py                 # PDF reading and vector creation
â”œâ”€â”€ chat.py                   # LangChain + LLaMA response pipeline
â”œâ”€â”€ pinecone_config.py        # Pinecone setup and API configuration
â”œâ”€â”€ static/                   # CSS and JavaScript for frontend
â”œâ”€â”€ templates/                # HTML template for chat UI
â”œâ”€â”€ requirements.txt          # Python dependency file
â””â”€â”€ README.md                 # Project documentation
```

---

## ğŸ“¦ Requirements

Install dependencies using:

```bash
pip install -r requirements.txt
```

Main Python Libraries:

* `flask`
* `langchain`
* `pinecone-client`
* `sentence-transformers`
* `llama-cpp-python`
* `PyMuPDF` (`fitz`)
* `dotenv`

---

## ğŸ“š Knowledge Source

> This project uses the PDF version of **The Gale Encyclopedia of Medicine**, a comprehensive and authoritative medical reference covering common conditions, treatments, and procedures.

---

## ğŸ¥ Use Cases

* ğŸ’¬ **Medical Query Assistant** for patients or learners
* ğŸ¥ Helpdesk Chatbot for hospitals and health websites
* ğŸ“š Educational Aid for medical students and interns
* ğŸ’¡ Research tool for semantic exploration of medical knowledge
* ğŸ” Prototype for domain-specific LLM-powered search engines

---

## ğŸš€ Feature Improvements

* ğŸ§  Add **multi-document support** with document tagging
* ğŸ—£ï¸ Integrate **speech-to-text** for voice-based interactions
* ğŸŒ Deploy using **cloud platforms** (Heroku, Railway, etc.)
* ğŸ” Add **user authentication** and history tracking
* ğŸŒ Incorporate **multi-language support** for wider accessibility
* ğŸ“ˆ Build analytics dashboard to track usage and trends

---
#



# ğŸ¥ Demo
https://github.com/user-attachments/assets/1334c4bb-d561-4011-a9f0-d1dc66e6dae0


---

# HOW TO RUN?
### STEPS:

Clone the repository

```bash
https://github.com/mmannat12/CareAI-MedicalBot.git
```

### STEP 1: CREATE CONDA ENVIRONMENT AFTER OPENING THE REPOSITORY

```bash
conda create -n medibot python=3.10 -y
```

```bash
conda activate medibot
```

### STEP 2 - INSTALL ALL THE REQUIREMENTS
```bash
 pip install -r requirements.txt
 ```
